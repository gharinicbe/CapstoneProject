{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def stem_block(input_tensor):\n",
    "    # First convolution layer with kernel (3*3*3) and stride=2\n",
    "    conv3_2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same')(input_tensor)\n",
    "    bn1 = tf.keras.layers.BatchNormalization()(conv3_2)\n",
    "    relu1 = tf.keras.layers.ReLU()(bn1)\n",
    "\n",
    "    # Second convolution layer with kernel (3*3*3) and stride=1\n",
    "    conv3_1 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same')(relu1)\n",
    "    bn2 = tf.keras.layers.BatchNormalization()(conv3_1)\n",
    "    relu2 = tf.keras.layers.ReLU()(bn2)\n",
    "\n",
    "    # Third convolution layer with kernel (3*3*3) and stride=2\n",
    "    conv3_2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same')(relu2)\n",
    "    bn3 = tf.keras.layers.BatchNormalization()(conv3_2)\n",
    "    relu3 = tf.keras.layers.ReLU()(bn3)\n",
    "\n",
    "    # Fourth convolution layer with kernel (3*3*3) and stride=1\n",
    "    conv3_1 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same')(relu3)\n",
    "    bn4 = tf.keras.layers.BatchNormalization()(conv3_1)\n",
    "    relu4 = tf.keras.layers.ReLU()(bn4)\n",
    "\n",
    "    return relu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48768963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_layer(input_tensor):\n",
    "    # First convolution layer with BatchNormalization and ReLU\n",
    "    conv1 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same')(input_tensor)\n",
    "    bn1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    relu1 = tf.keras.layers.ReLU()(bn1)\n",
    "\n",
    "    # Second convolution layer with BatchNormalization\n",
    "    conv2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same')(relu1)\n",
    "    bn2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "\n",
    "    # Add the input tensor to the output of the second convolution layer\n",
    "    added = tf.keras.layers.Add()([bn2, input_tensor])\n",
    "    relu2 = tf.keras.layers.ReLU()(added)\n",
    "\n",
    "    # Third convolution layer with BatchNormalization and ReLU\n",
    "    conv3 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same')(relu2)\n",
    "    bn3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    relu3 = tf.keras.layers.ReLU()(bn3)\n",
    "\n",
    "    # Fourth convolution layer with BatchNormalization\n",
    "    conv4 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same')(relu3)\n",
    "    bn4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "\n",
    "    # Add the output of the fourth convolution layer to the previous layer\n",
    "    added2 = tf.keras.layers.Add()([bn4, relu2])\n",
    "    relu4 = tf.keras.layers.ReLU()(added2)\n",
    "\n",
    "    return relu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6ecc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, Add, MaxPooling3D\n",
    "\n",
    "def short_term_memory_self_attention_block(x):\n",
    "    # Apply the custom_layer function\n",
    "    custom_conv = custom_layer(x)\n",
    "\n",
    "    # Implement the first downsampling block (MaxPooling3D)\n",
    "    downsampling1 = MaxPooling3D(pool_size=(2, 2, 2))(custom_conv)\n",
    "\n",
    "    # Second Short-Term Memory Self-Attention Block\n",
    "    short_term_attention2 = custom_layer(downsampling1)\n",
    "\n",
    "    # Implement the second downsampling block (MaxPooling3D)\n",
    "    downsampling2 = MaxPooling3D(pool_size=(2, 2, 2))(short_term_attention2)\n",
    "\n",
    "    # Third convolutional layer\n",
    "    conv3 = custom_layer(x)\n",
    "\n",
    "    # Resize conv3 to have the same spatial shape as resized_short_term_attention2\n",
    "    conv3_resized = tf.image.resize(conv3, size=(12, 12, 12))  # Resize all dimensions\n",
    "\n",
    "    # Ensure both tensors have the same number of channels (last dimension)\n",
    "    num_channels = 32  # Adjust this based on the number of channels in your tensors\n",
    "    conv3_resized = tf.keras.layers.Conv3D(num_channels, kernel_size=(1, 1, 1))(conv3_resized)\n",
    "\n",
    "    print(conv3_resized.shape)\n",
    "\n",
    "    # Resize short_term_attention2 to match the shape of conv3\n",
    "    resized_short_term_attention2 = tf.image.resize(short_term_attention2, size=(12, 12, 12))  # Resize all dimensions\n",
    "\n",
    "    # Ensure both tensors have the same number of channels (last dimension)\n",
    "    num_channels = 32  # Adjust this based on the number of channels in your tensors\n",
    "    resized_short_term_attention2 = tf.keras.layers.Conv3D(num_channels, kernel_size=(1, 1, 1))(resized_short_term_attention2)\n",
    "\n",
    "    # Now they both have the same shape, and you can add them\n",
    "    merged = Add()([resized_short_term_attention2, conv3_resized])\n",
    "\n",
    "    # Implement the fourth convolution layer\n",
    "    conv4 = custom_layer(merged)\n",
    "\n",
    "    # Implement the third downsampling block (MaxPooling3D)\n",
    "    downsampling3 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n",
    "\n",
    "    return downsampling3  # Return the output of the third downsampling block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c79855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<numpy.lib.npyio.NpzFile object at 0x000001AA8548A310>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "loaded_data = np.load(\"C:/Users/Harini Balaji/HariniBalaji/output_directory_for_preprocessed_data/preprocessed_case_00000.npz\")\n",
    "\n",
    "# Print the keys available in the loaded .npz file\n",
    "print(loaded_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a87a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img', 'seg']\n",
      "Key: img, Shape: (96, 96, 96)\n",
      "Key: seg, Shape: (96, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "loaded_data = np.load(\"C:/Users/Harini Balaji/HariniBalaji/output_directory_for_preprocessed_data/preprocessed_case_00000.npz\")\n",
    "\n",
    "# Convert the KeysView object to a list of keys\n",
    "keys_list = list(loaded_data.keys())\n",
    "\n",
    "# Print the list of keys\n",
    "print(keys_list)\n",
    "\n",
    "# Iterate through the keys and access the data\n",
    "for key in keys_list:\n",
    "    data_array = loaded_data[key]\n",
    "    # Use data_array as needed\n",
    "    print(f\"Key: {key}, Shape: {data_array.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9c4b8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (209, 96, 96, 96), Labels shape: (209, 96, 96, 96)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed data from output_dir\n",
    "data_dir = \"C:/Users/Harini Balaji/HariniBalaji/output_directory_for_preprocessed_data\"\n",
    "data_files = os.listdir(data_dir)\n",
    "import numpy as np\n",
    "\n",
    "# Define the desired shape\n",
    "desired_shape = (96, 96, 96)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the .npz files and load data and labels\n",
    "for data_file in os.listdir(data_dir):\n",
    "    if data_file.endswith(\".npz\"):\n",
    "        with np.load(os.path.join(data_dir, data_file)) as npz:\n",
    "            loaded_data = npz[\"img\"]\n",
    "            loaded_labels = npz[\"seg\"]\n",
    "            \n",
    "            # Check if the loaded data has the desired shape\n",
    "            if loaded_data.shape != desired_shape:\n",
    "                # Resize the data and labels to the desired shape\n",
    "                resized_data = np.zeros(desired_shape, dtype=loaded_data.dtype)\n",
    "                resized_labels = np.zeros(desired_shape, dtype=loaded_labels.dtype)\n",
    "                min_dim = min(desired_shape[0], loaded_data.shape[0])\n",
    "                resized_data[:min_dim, :, :] = loaded_data[:min_dim, :, :]\n",
    "                resized_labels[:min_dim, :, :] = loaded_labels[:min_dim, :, :]\n",
    "                data.append(resized_data)\n",
    "                labels.append(resized_labels)\n",
    "            else:\n",
    "                data.append(loaded_data)\n",
    "                labels.append(loaded_labels)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Now, you should have NumPy arrays with a consistent shape (96, 96, 96)\n",
    "print(f\"Data shape: {data.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "# Shuffle and batch the dataset\n",
    "batch_size = 32  # Adjust this batch size according to your needs\n",
    "dataset = dataset.shuffle(buffer_size=len(data)).batch(batch_size)\n",
    "print(\"Done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a69e115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 24, 24, 32) dtype=float32 (created by layer 're_lu_3')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Define your input shape\n",
    "input_shape = (96, 96, 96,1)\n",
    "\n",
    "# Create the input tensor\n",
    "input_tensor = Input(shape=input_shape, name='dataset')\n",
    "\n",
    "# Now you can use `input_tensor` in your model definition.\n",
    "stem_output = stem_block(input_tensor)\n",
    "stem_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029c44f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tf.image.resize\" (type TFOpLambda).\n\n'images' must have either 3 or 4 dimensions.\n\nCall arguments received by layer \"tf.image.resize\" (type TFOpLambda):\n  • images=tf.Tensor(shape=(None, 24, 24, 24, 32), dtype=float32)\n  • size=('12', '12', '12')\n  • method=bilinear\n  • preserve_aspect_ratio=False\n  • antialias=False\n  • name=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23228\\1062883197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create short-term memory self-attention blocks and connect them in series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_short_term_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mshort_term_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshort_term_memory_self_attention_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshort_term_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mshort_term_outputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshort_term_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23228\\1011684847.py\u001b[0m in \u001b[0;36mshort_term_memory_self_attention_block\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Resize conv3 to have the same spatial shape as resized_short_term_attention2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mconv3_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Resize all dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Ensure both tensors have the same number of channels (last dimension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\HariniLearn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\HariniLearn\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         ):\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\HariniLearn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.image.resize\" (type TFOpLambda).\n\n'images' must have either 3 or 4 dimensions.\n\nCall arguments received by layer \"tf.image.resize\" (type TFOpLambda):\n  • images=tf.Tensor(shape=(None, 24, 24, 24, 32), dtype=float32)\n  • size=('12', '12', '12')\n  • method=bilinear\n  • preserve_aspect_ratio=False\n  • antialias=False\n  • name=None"
     ]
    }
   ],
   "source": [
    "# Define the number of short-term memory self-attention blocks\n",
    "num_short_term_blocks = 3  # You can adjust this number\n",
    "\n",
    "# Create a list to store the outputs of short-term memory self-attention blocks\n",
    "short_term_outputs = [stem_output]\n",
    "\n",
    "# Create short-term memory self-attention blocks and connect them in series\n",
    "for _ in range(num_short_term_blocks):\n",
    "    short_term_output = short_term_memory_self_attention_block(short_term_outputs[-1])\n",
    "    short_term_outputs.append(short_term_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc398d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
